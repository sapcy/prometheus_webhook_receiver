map[Content-Length:[1679] Content-Type:[application/json] User-Agent:[Alertmanager/0.25.0]]
webhook-receiver.portal.svc:8111
{
    "receiver": "webhook-receiver",
    "status": "firing",
    "alerts": [
        {
            "status": "firing",
            "labels": {
                "alertname": "TargetDown",
                "job": "example-vault",
                "prometheus": "monitoring/example-prometheus",
                "severity": "warning"
            },
            "annotations": {
                "description": "100% of the example-vault/ targets in  namespace are down.",
                "runbook_url": "https://runbooks.prometheus-operator.dev/runbooks/general/targetdown",
                "summary": "One or more targets are unreachable."
            },
            "startsAt": "2024-03-19T08:54:34.594Z",
            "endsAt": "0001-01-01T00:00:00Z",
            "generatorURL": "http://example-prometheus.monitoring:9090/graph?g0.expr=100+%2A+%28count+by+%28cluster%2C+job%2C+namespace%2C+service%29+%28up+%3D%3D+0%29+%2F+count+by+%28cluster%2C+job%2C+namespace%2C+service%29+%28up%29%29+%3E+10\u0026g0.tab=1",
            "fingerprint": "db0dbe1e7f9f1338"
        },
        {
            "status": "firing",
            "labels": {
                "alertname": "KubeProxyDown",
                "prometheus": "monitoring/example-prometheus",
                "severity": "critical"
            },
            "annotations": {
                "description": "KubeProxy has disappeared from Prometheus target discovery.",
                "runbook_url": "https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubeproxydown",
                "summary": "Target disappeared from Prometheus target discovery."
            },
            "startsAt": "2024-03-19T08:54:33.662Z",
            "endsAt": "0001-01-01T00:00:00Z",
            "generatorURL": "http://example-prometheus.monitoring:9090/graph?g0.expr=absent%28up%7Bjob%3D%22kube-proxy%22%7D+%3D%3D+1%29\u0026g0.tab=1",
            "fingerprint": "efb2e2e421060fbe"
        }
    ],
    "groupLabels": {},
    "commonLabels": {
        "prometheus": "monitoring/example-prometheus"
    },
    "commonAnnotations": {},
    "externalURL": "http://example-alertmanager.monitoring:9093",
    "version": "4",
    "groupKey": "{}/{alertname=~\".*\"}:{}",
    "truncatedAlerts": 0
}
[GIN] 2024/03/19 - 08:55:03 | 200 |     1.11641ms |   10.233.111.47 | POST     "/webhook"


map[Content-Length:[2391] Content-Type:[application/json] User-Agent:[Alertmanager/0.25.0]]
webhook-receiver.portal.svc:8111
{
    "receiver": "webhook-receiver",
    "status": "firing",
    "alerts": [
        {
            "status": "firing",
            "labels": {
                "alertname": "TargetDown",
                "job": "example-keyclo-http",
                "namespace": "infra",
                "prometheus": "monitoring/example-prometheus",
                "service": "example-keyclo-http",
                "severity": "warning"
            },
            "annotations": {
                "description": "100% of the example-keyclo-http/example-keyclo-http targets in infra namespace are down.",
                "runbook_url": "https://runbooks.prometheus-operator.dev/runbooks/general/targetdown",
                "summary": "One or more targets are unreachable."
            },
            "startsAt": "2024-03-19T08:54:34.594Z",
            "endsAt": "0001-01-01T00:00:00Z",
            "generatorURL": "http://example-prometheus.monitoring:9090/graph?g0.expr=100+%2A+%28count+by+%28cluster%2C+job%2C+namespace%2C+service%29+%28up+%3D%3D+0%29+%2F+count+by+%28cluster%2C+job%2C+namespace%2C+service%29+%28up%29%29+%3E+10\u0026g0.tab=1",
            "fingerprint": "a495f79fc89f3fd4"
        },
        {
            "status": "firing",
            "labels": {
                "alertname": "KubePodNotReady",
                "namespace": "infra",
                "pod": "example-proxy-kong-b49cffc69-5gj8q",
                "prometheus": "monitoring/example-prometheus",
                "severity": "warning"
            },
            "annotations": {
                "description": "Pod infra/example-proxy-kong-b49cffc69-5gj8q has been in a non-ready state for longer than 15 minutes.",
                "runbook_url": "https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubepodnotready",
                "summary": "Pod has been in a non-ready state for more than 15 minutes."
            },
            "startsAt": "2024-03-19T08:54:42.396Z",
            "endsAt": "0001-01-01T00:00:00Z",
            "generatorURL": "http://example-prometheus.monitoring:9090/graph?g0.expr=sum+by+%28namespace%2C+pod%2C+cluster%29+%28max+by+%28namespace%2C+pod%2C+cluster%29+%28kube_pod_status_phase%7Bjob%3D%22kube-state-metrics%22%2Cnamespace%3D~%22.%2A%22%2Cphase%3D~%22Pending%7CUnknown%7CFailed%22%7D%29+%2A+on+%28namespace%2C+pod%2C+cluster%29+group_left+%28owner_kind%29+topk+by+%28namespace%2C+pod%2C+cluster%29+%281%2C+max+by+%28namespace%2C+pod%2C+owner_kind%2C+cluster%29+%28kube_pod_owner%7Bowner_kind%21%3D%22Job%22%7D%29%29%29+%3E+0\u0026g0.tab=1",
            "fingerprint": "70e1d24a7755916b"
        }
    ],
    "groupLabels": {
        "namespace": "infra"
    },
    "commonLabels": {
        "namespace": "infra",
        "prometheus": "monitoring/example-prometheus",
        "severity": "warning"
    },
    "commonAnnotations": {},
    "externalURL": "http://example-alertmanager.monitoring:9093",
    "version": "4",
    "groupKey": "{}/{alertname=~\".*\"}:{namespace=\"infra\"}",
    "truncatedAlerts": 0
}
[GIN] 2024/03/19 - 08:55:04 | 200 |      459.09µs |   10.233.111.47 | POST     "/webhook"


map[Content-Length:[4128] Content-Type:[application/json] User-Agent:[Alertmanager/0.25.0]]
webhook-receiver.portal.svc:8111
{
    "receiver": "webhook-receiver",
    "status": "firing",
    "alerts": [
        {
            "status": "firing",
            "labels": {
                "alertname": "TargetDown",
                "job": "kube-proxy",
                "namespace": "kube-system",
                "prometheus": "monitoring/example-prometheus",
                "service": "example-kube-proxy",
                "severity": "warning"
            },
            "annotations": {
                "description": "100% of the kube-proxy/example-kube-proxy targets in kube-system namespace are down.",
                "runbook_url": "https://runbooks.prometheus-operator.dev/runbooks/general/targetdown",
                "summary": "One or more targets are unreachable."
            },
            "startsAt": "2024-03-19T08:54:34.594Z",
            "endsAt": "0001-01-01T00:00:00Z",
            "generatorURL": "http://example-prometheus.monitoring:9090/graph?g0.expr=100+%2A+%28count+by+%28cluster%2C+job%2C+namespace%2C+service%29+%28up+%3D%3D+0%29+%2F+count+by+%28cluster%2C+job%2C+namespace%2C+service%29+%28up%29%29+%3E+10\u0026g0.tab=1",
            "fingerprint": "f706e71326fc9281"
        },
        {
            "status": "firing",
            "labels": {
                "alertname": "TargetDown",
                "job": "kubelet",
                "namespace": "kube-system",
                "prometheus": "monitoring/example-prometheus",
                "service": "example-kubelet",
                "severity": "warning"
            },
            "annotations": {
                "description": "20% of the kubelet/example-kubelet targets in kube-system namespace are down.",
                "runbook_url": "https://runbooks.prometheus-operator.dev/runbooks/general/targetdown",
                "summary": "One or more targets are unreachable."
            },
            "startsAt": "2024-03-19T08:54:34.594Z",
            "endsAt": "0001-01-01T00:00:00Z",
            "generatorURL": "http://example-prometheus.monitoring:9090/graph?g0.expr=100+%2A+%28count+by+%28cluster%2C+job%2C+namespace%2C+service%29+%28up+%3D%3D+0%29+%2F+count+by+%28cluster%2C+job%2C+namespace%2C+service%29+%28up%29%29+%3E+10\u0026g0.tab=1",
            "fingerprint": "28b7f69fbd365971"
        },
        {
            "status": "firing",
            "labels": {
                "alertname": "KubePodNotReady",
                "namespace": "kube-system",
                "pod": "nginx-proxy-example-worker-2",
                "prometheus": "monitoring/example-prometheus",
                "severity": "warning"
            },
            "annotations": {
                "description": "Pod kube-system/nginx-proxy-example-worker-2 has been in a non-ready state for longer than 15 minutes.",
                "runbook_url": "https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubepodnotready",
                "summary": "Pod has been in a non-ready state for more than 15 minutes."
            },
            "startsAt": "2024-03-19T08:54:42.396Z",
            "endsAt": "0001-01-01T00:00:00Z",
            "generatorURL": "http://example-prometheus.monitoring:9090/graph?g0.expr=sum+by+%28namespace%2C+pod%2C+cluster%29+%28max+by+%28namespace%2C+pod%2C+cluster%29+%28kube_pod_status_phase%7Bjob%3D%22kube-state-metrics%22%2Cnamespace%3D~%22.%2A%22%2Cphase%3D~%22Pending%7CUnknown%7CFailed%22%7D%29+%2A+on+%28namespace%2C+pod%2C+cluster%29+group_left+%28owner_kind%29+topk+by+%28namespace%2C+pod%2C+cluster%29+%281%2C+max+by+%28namespace%2C+pod%2C+owner_kind%2C+cluster%29+%28kube_pod_owner%7Bowner_kind%21%3D%22Job%22%7D%29%29%29+%3E+0\u0026g0.tab=1",
            "fingerprint": "443236e428c461eb"
        },
        {
            "status": "firing",
            "labels": {
                "alertname": "CPUThrottlingHigh",
                "container": "calico-node",
                "namespace": "kube-system",
                "pod": "calico-node-852d4",
                "prometheus": "monitoring/example-prometheus",
                "severity": "info"
            },
            "annotations": {
                "description": "48.6% throttling of CPU in namespace kube-system for container calico-node in pod calico-node-852d4.",
                "runbook_url": "https://runbooks.prometheus-operator.dev/runbooks/kubernetes/cputhrottlinghigh",
                "summary": "Processes experience elevated CPU throttling."
            },
            "startsAt": "2024-03-19T08:54:56.576Z",
            "endsAt": "0001-01-01T00:00:00Z",
            "generatorURL": "http://example-prometheus.monitoring:9090/graph?g0.expr=sum+by+%28container%2C+pod%2C+namespace%29+%28increase%28container_cpu_cfs_throttled_periods_total%7Bcontainer%21%3D%22%22%7D%5B5m%5D%29%29+%2F+sum+by+%28container%2C+pod%2C+namespace%29+%28increase%28container_cpu_cfs_periods_total%5B5m%5D%29%29+%3E+%2825+%2F+100%29\u0026g0.tab=1",
            "fingerprint": "a31387160a1e4547"
        }
    ],
    "groupLabels": {
        "namespace": "kube-system"
    },
    "commonLabels": {
        "namespace": "kube-system",
        "prometheus": "monitoring/example-prometheus"
    },
    "commonAnnotations": {},
    "externalURL": "http://example-alertmanager.monitoring:9093",
    "version": "4",
    "groupKey": "{}/{alertname=~\".*\"}:{namespace=\"kube-system\"}",
    "truncatedAlerts": 0
}
[GIN] 2024/03/19 - 08:55:04 | 200 |     372.226µs |   10.233.111.47 | POST     "/webhook"


map[Content-Length:[2486] Content-Type:[application/json] User-Agent:[Alertmanager/0.25.0]]
webhook-receiver.portal.svc:8111
{
    "receiver": "webhook-receiver",
    "status": "firing",
    "alerts": [
        {
            "status": "resolved",
            "labels": {
                "alertname": "PrometheusOperatorSyncFailed",
                "container": "kube-prometheus-stack",
                "controller": "alertmanager",
                "endpoint": "https",
                "instance": "10.233.111.22:10250",
                "job": "example-operator",
                "namespace": "monitoring",
                "pod": "example-operator-66d4d5df47-hvtmb",
                "prometheus": "monitoring/example-prometheus",
                "service": "example-operator",
                "severity": "warning",
                "status": "failed"
            },
            "annotations": {
                "description": "Controller alertmanager in monitoring namespace fails to reconcile 1 objects.",
                "runbook_url": "https://runbooks.prometheus-operator.dev/runbooks/prometheus-operator/prometheusoperatorsyncfailed",
                "summary": "Last controller reconciliation failed"
            },
            "startsAt": "2024-03-19T08:54:41.121Z",
            "endsAt": "2024-03-19T08:55:11.121Z",
            "generatorURL": "http://example-prometheus.monitoring:9090/graph?g0.expr=min_over_time%28prometheus_operator_syncs%7Bjob%3D%22example-operator%22%2Cnamespace%3D%22monitoring%22%2Cstatus%3D%22failed%22%7D%5B5m%5D%29+%3E+0\u0026g0.tab=1",
            "fingerprint": "615df6a533c3ed0c"
        },
        {
            "status": "firing",
            "labels": {
                "alertname": "PrometheusNotConnectedToAlertmanagers",
                "container": "prometheus",
                "endpoint": "http-web",
                "instance": "10.233.111.46:9090",
                "job": "example-prometheus",
                "namespace": "monitoring",
                "pod": "prometheus-example-prometheus-0",
                "prometheus": "monitoring/example-prometheus",
                "service": "example-prometheus",
                "severity": "warning"
            },
            "annotations": {
                "description": "Prometheus monitoring/prometheus-example-prometheus-0 is not connected to any Alertmanagers.",
                "runbook_url": "https://runbooks.prometheus-operator.dev/runbooks/prometheus/prometheusnotconnectedtoalertmanagers",
                "summary": "Prometheus is not connected to any Alertmanagers."
            },
            "startsAt": "2024-03-19T08:54:48.04Z",
            "endsAt": "0001-01-01T00:00:00Z",
            "generatorURL": "http://example-prometheus.monitoring:9090/graph?g0.expr=max_over_time%28prometheus_notifications_alertmanagers_discovered%7Bjob%3D%22example-prometheus%22%2Cnamespace%3D%22monitoring%22%7D%5B5m%5D%29+%3C+1\u0026g0.tab=1",
            "fingerprint": "0af15794fd098363"
        }
    ],
    "groupLabels": {
        "namespace": "monitoring"
    },
    "commonLabels": {
        "namespace": "monitoring",
        "prometheus": "monitoring/example-prometheus",
        "severity": "warning"
    },
    "commonAnnotations": {},
    "externalURL": "http://example-alertmanager.monitoring:9093",
    "version": "4",
    "groupKey": "{}/{alertname=~\".*\"}:{namespace=\"monitoring\"}",
    "truncatedAlerts": 0
}
[GIN] 2024/03/19 - 09:00:11 | 200 |     152.436µs |   10.233.111.47 | POST     "/webhook"